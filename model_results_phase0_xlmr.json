{
  "model_name": "xlm-roberta-base",
  "epochs_trained": 16,
  "best_val_loss": 0.7812828705424354,
  "val_f1_micro": [
    0.13312613312613314,
    0.1557254196642686,
    0.18360115368768026,
    0.19463986599664992,
    0.1985656268901754,
    0.20336890378340242,
    0.20656610470275066,
    0.19542445319701668,
    0.21523603035379915,
    0.2196486406909412,
    0.2216122801667175,
    0.23428815733219324,
    0.23021285389543295,
    0.22293697859081316,
    0.22770398481973433,
    0.2302295918367347
  ],
  "val_loss": [
    1.1301093215034121,
    1.044509544259026,
    0.9414320900326684,
    0.8822138706843058,
    0.8635410751615252,
    0.836631885596684,
    0.8123235475449335,
    0.8178999963260832,
    0.8218290096237546,
    0.7871828845569065,
    0.8072218838192168,
    0.7864500568026588,
    0.7812828705424354,
    0.7904624144236246,
    0.7936634733563378,
    0.7900692479951041
  ],
  "train_loss": [
    1.9265286260181003,
    1.0920474008908347,
    0.9900105283373878,
    0.9092023117201669,
    0.853998047018808,
    0.8189249823963831,
    0.7820600942959861,
    0.7499564242741418,
    0.7282073223401629,
    0.7069107795518542,
    0.6845092598407988,
    0.6716210075787136,
    0.6576044602053506,
    0.6440899130843935,
    0.6348300391719455,
    0.6239430544868348
  ],
  "config": {
    "batch_size": 16,
    "learning_rate": 2e-05,
    "h_lambda": 2.0,
    "patience": 3,
    "pos_weight": 29.12358393408857,
    "model_output_path": "models/phase0_xlmr_best_model.bin"
  }
}