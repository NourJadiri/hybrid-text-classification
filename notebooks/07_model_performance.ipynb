{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2538270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "# Set the current working directory to the project root\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21746730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NARRATIVE_THRESHOLD = 0.89\n",
    "SUBNARRATIVE_THRESHOLD = 0.80\n",
    "BEST_MODEL_CHECKPOINT_PATH = 'models/phase0_xlmr_best_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1b5a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations and taxonomy...\n",
      "Mapping labels to IDs and creating binarized vectors...\n",
      "Splitting dataset into train, validation, and test sets...\n",
      "Dataset split sizes: Train=1005, Validation=331, Test=363\n",
      "Number of training examples: 1005\n",
      "Number of validation examples: 331\n",
      "Number of testing examples: 363\n",
      "Number of labels: 117\n",
      "Mapping labels to IDs and creating binarized vectors...\n",
      "Splitting dataset into train, validation, and test sets...\n",
      "Dataset split sizes: Train=1005, Validation=331, Test=363\n",
      "Number of training examples: 1005\n",
      "Number of validation examples: 331\n",
      "Number of testing examples: 363\n",
      "Number of labels: 117\n"
     ]
    }
   ],
   "source": [
    "from src.scripts.data_preparation import prepare_dataframes\n",
    "\n",
    "# Define constants\n",
    "DATA_FOLDER = 'data'\n",
    "\n",
    "# Prepare the dataframes\n",
    "(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    id_to_label,\n",
    "    label_to_id,\n",
    "    parent_child_pairs,\n",
    ") = prepare_dataframes(data_folder=DATA_FOLDER)\n",
    "\n",
    "num_total_labels = len(id_to_label)\n",
    "\n",
    "print(f\"Number of training examples: {len(train_df)}\")\n",
    "print(f\"Number of validation examples: {len(val_df)}\")\n",
    "print(f\"Number of testing examples: {len(test_df)}\")\n",
    "print(f\"Number of labels: {num_total_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb32c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing Training Set Class Distribution ---\n",
      "Calculating class distribution...\n",
      "Class distribution calculation complete.\n",
      "\n",
      "Top 20 Rarest Classes in Training Data:\n",
      "                                                 label  count          level\n",
      "99   CC: Green policies are geopolitical instrument...      1  Sub-narrative\n",
      "113  CC: Downplaying climate change: Sea levels are...      1  Sub-narrative\n",
      "86   CC: Questioning the measurements and science: ...      1  Sub-narrative\n",
      "68   CC: Green policies are geopolitical instrument...      1  Sub-narrative\n",
      "74   CC: Downplaying climate change: Weather sugges...      2  Sub-narrative\n",
      "95   CC: Downplaying climate change: CO2 concentrat...      2  Sub-narrative\n",
      "111  URW: Blaming the war on others rather than the...      2  Sub-narrative\n",
      "93   URW: Praise of Russia: Russian invasion has st...      2  Sub-narrative\n",
      "112  URW: Distrust towards Media: Ukrainian media c...      2  Sub-narrative\n",
      "104  CC: Questioning the measurements and science: ...      2  Sub-narrative\n",
      "103  CC: Downplaying climate change: Ice is not mel...      2  Sub-narrative\n",
      "100  CC: Green policies are geopolitical instrument...      3  Sub-narrative\n",
      "106  CC: Questioning the measurements and science: ...      3  Sub-narrative\n",
      "114  URW: Discrediting the West, Diplomacy: The Wes...      3  Sub-narrative\n",
      "94   CC: Controversy about green technologies: Rene...      3  Sub-narrative\n",
      "108                  URW: Overpraising the West: Other      3  Sub-narrative\n",
      "80   URW: Overpraising the West: NATO will destroy ...      4  Sub-narrative\n",
      "79   CC: Climate change is beneficial: Temperature ...      4  Sub-narrative\n",
      "107  CC: Downplaying climate change: Humans and nat...      4  Sub-narrative\n",
      "109  URW: Speculating war outcomes: Russian army wi...      4  Sub-narrative\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Analyze Class Distribution on the Training Set ---\n",
    "from src.utils.metrics import get_class_distribution\n",
    "\n",
    "\n",
    "print(\"--- Analyzing Training Set Class Distribution ---\")\n",
    "# Use the reusable function to get the counts\n",
    "train_class_distribution = get_class_distribution(train_df, id_to_label)\n",
    "# Display the rarest classes, which are your primary candidates for augmentation\n",
    "print(\"\\nTop 20 Rarest Classes in Training Data:\")\n",
    "print(train_class_distribution.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab0c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset and dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=117, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_management.datasets import NarrativeClassificationDataset\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(\"Creating validation dataset and dataloader...\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_total_labels,\n",
    "    problem_type='multi_label_classification',\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(BEST_MODEL_CHECKPOINT_PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7399d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset created with 331 examples.\n",
      "Validation dataloader created with batch size 16.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "val_dataset = NarrativeClassificationDataset(val_df, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Validation dataset created with {len(val_dataset)} examples.\")\n",
    "print(f\"Validation dataloader created with batch size {BATCH_SIZE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d459bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Per-Class F1 Scores on Validation Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Raw Predictions:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Raw Predictions: 100%|██████████| 21/21 [00:05<00:00,  3.71it/s]\n",
      "Getting Raw Predictions: 100%|██████████| 21/21 [00:05<00:00,  3.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Analyze Per-Class F1 Scores on the Validation Set ---\n",
    "from src.training.engine import get_raw_predictions, compute_metrics\n",
    "\n",
    "\n",
    "print(\"\\n--- Analyzing Per-Class F1 Scores on Validation Set ---\")\n",
    "# First, get the predictions and true labels from your validation set\n",
    "val_logits, val_true_labels = get_raw_predictions(model, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ef17ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Per-Class F1 Scores with Best Thresholds ---\n",
      "Calculating per-class F1 scores with per-level thresholds...\n",
      "Probabilities Stats: Min=0.0255, Max=0.9744, Mean=0.3030\n",
      "Narrative Threshold: 0.89, Sub-narrative Threshold: 0.8\n",
      "Total number of positive predictions made (after thresholding): 2084\n",
      "Per-class F1 score calculation complete.\n",
      "\n",
      "Per-Class F1 Scores (sorted by F1 score):\n",
      "                                                 label  f1_score\n",
      "1                     CC: Climate change is beneficial  0.000000\n",
      "2             CC: Controversy about green technologies  0.000000\n",
      "6                       CC: Downplaying climate change  0.000000\n",
      "7      CC: Green policies are geopolitical instruments  0.000000\n",
      "10                                               Other  0.000000\n",
      "15                         URW: Distrust towards Media  0.000000\n",
      "9         CC: Questioning the measurements and science  0.000000\n",
      "30   CC: Controversy about green technologies: Nucl...  0.000000\n",
      "24   CC: Amplifying Climate Fears: Earth will be un...  0.000000\n",
      "26   CC: Amplifying Climate Fears: Whatever we do i...  0.000000\n",
      "27   CC: Climate change is beneficial: CO2 is benef...  0.000000\n",
      "28             CC: Climate change is beneficial: Other  0.000000\n",
      "21                       URW: Speculating war outcomes  0.000000\n",
      "18                          URW: Overpraising the West  0.000000\n",
      "17             URW: Negative Consequences for the West  0.000000\n",
      "16   URW: Hidden plots by secret schemes of powerfu...  0.000000\n",
      "31     CC: Controversy about green technologies: Other  0.000000\n",
      "29   CC: Climate change is beneficial: Temperature ...  0.000000\n",
      "50   CC: Downplaying climate change: Human activiti...  0.000000\n",
      "51   CC: Downplaying climate change: Humans and nat...  0.000000\n",
      "52   CC: Downplaying climate change: Ice is not mel...  0.000000\n",
      "53               CC: Downplaying climate change: Other  0.000000\n",
      "54   CC: Downplaying climate change: Sea levels are...  0.000000\n",
      "47   CC: Criticism of institutions and authorities:...  0.000000\n",
      "40   CC: Criticism of climate policies: Climate pol...  0.000000\n",
      "43   CC: Criticism of institutions and authorities:...  0.000000\n",
      "46   CC: Criticism of institutions and authorities:...  0.000000\n",
      "37   CC: Criticism of climate movement: Climate mov...  0.000000\n",
      "35   CC: Criticism of climate movement: Ad hominem ...  0.000000\n",
      "34   CC: Controversy about green technologies: Rene...  0.000000\n",
      "33   CC: Controversy about green technologies: Rene...  0.000000\n",
      "32   CC: Controversy about green technologies: Rene...  0.000000\n",
      "56   CC: Downplaying climate change: Weather sugges...  0.000000\n",
      "57   CC: Green policies are geopolitical instrument...  0.000000\n",
      "58   CC: Green policies are geopolitical instrument...  0.000000\n",
      "59   CC: Green policies are geopolitical instrument...  0.000000\n",
      "63   CC: Questioning the measurements and science: ...  0.000000\n",
      "62   CC: Hidden plots by secret schemes of powerful...  0.000000\n",
      "55   CC: Downplaying climate change: Temperature in...  0.000000\n",
      "48   CC: Downplaying climate change: CO2 concentrat...  0.000000\n",
      "49   CC: Downplaying climate change: Climate cycles...  0.000000\n",
      "106  URW: Praise of Russia: Russia has internationa...  0.000000\n",
      "113               URW: Speculating war outcomes: Other  0.000000\n",
      "116  URW: Speculating war outcomes: Ukrainian army ...  0.000000\n",
      "92                  URW: Distrust towards Media: Other  0.000000\n",
      "91   URW: Discrediting the West, Diplomacy: West is...  0.000000\n",
      "93   URW: Distrust towards Media: Ukrainian media c...  0.000000\n",
      "95   URW: Hidden plots by secret schemes of powerfu...  0.000000\n",
      "80   URW: Discrediting Ukraine: Rewriting Ukraine’s...  0.000000\n",
      "81   URW: Discrediting Ukraine: Situation in Ukrain...  0.000000\n",
      "82   URW: Discrediting Ukraine: Ukraine is a hub fo...  0.000000\n",
      "84   URW: Discrediting Ukraine: Ukraine is associat...  0.000000\n",
      "87   URW: Discrediting the West, Diplomacy: The EU ...  0.000000\n",
      "85   URW: Discrediting the West, Diplomacy: Diploma...  0.000000\n",
      "90   URW: Discrediting the West, Diplomacy: The Wes...  0.000000\n",
      "89   URW: Discrediting the West, Diplomacy: The Wes...  0.000000\n",
      "94   URW: Distrust towards Media: Western media is ...  0.000000\n",
      "78   URW: Discrediting Ukraine: Discrediting Ukrain...  0.000000\n",
      "73   URW: Blaming the war on others rather than the...  0.000000\n",
      "69   URW: Amplifying war-related fears: NATO should...  0.000000\n",
      "67   CC: Questioning the measurements and science: ...  0.000000\n",
      "66   CC: Questioning the measurements and science: ...  0.000000\n",
      "65   CC: Questioning the measurements and science: ...  0.000000\n",
      "64   CC: Questioning the measurements and science: ...  0.000000\n",
      "115  URW: Speculating war outcomes: Russian army wi...  0.000000\n",
      "114  URW: Speculating war outcomes: Russian army is...  0.000000\n",
      "112  URW: Russia is the Victim: UA is anti-RU extre...  0.000000\n",
      "102  URW: Overpraising the West: The West has the s...  0.000000\n",
      "100                  URW: Overpraising the West: Other  0.000000\n",
      "99   URW: Overpraising the West: NATO will destroy ...  0.000000\n",
      "98   URW: Negative Consequences for the West: The c...  0.000000\n",
      "108  URW: Praise of Russia: Russian invasion has st...  0.000000\n",
      "104  URW: Praise of Russia: Praise of Russian Presi...  0.000000\n",
      "103                       URW: Praise of Russia: Other  0.000000\n",
      "101  URW: Overpraising the West: The West belongs i...  0.000000\n",
      "97   URW: Negative Consequences for the West: Sanct...  0.000000\n",
      "68   URW: Amplifying war-related fears: By continui...  0.074074\n",
      "42            CC: Criticism of climate policies: Other  0.090909\n",
      "38            CC: Criticism of climate movement: Other  0.117647\n",
      "111  URW: Russia is the Victim: The West is russoph...  0.125000\n",
      "36   CC: Criticism of climate movement: Climate mov...  0.133333\n",
      "23   CC: Amplifying Climate Fears: Doomsday scenari...  0.142857\n",
      "39   CC: Criticism of climate policies: Climate pol...  0.148148\n",
      "71   URW: Amplifying war-related fears: Russia will...  0.166667\n",
      "96      URW: Negative Consequences for the West: Other  0.173913\n",
      "75   URW: Blaming the war on others rather than the...  0.173913\n",
      "60   CC: Hidden plots by secret schemes of powerful...  0.181818\n",
      "8    CC: Hidden plots by secret schemes of powerful...  0.181818\n",
      "70            URW: Amplifying war-related fears: Other  0.228571\n",
      "107  URW: Praise of Russia: Russia is a guarantor o...  0.243243\n",
      "105  URW: Praise of Russia: Praise of Russian milit...  0.253165\n",
      "76   URW: Discrediting Ukraine: Discrediting Ukrain...  0.284091\n",
      "83   URW: Discrediting Ukraine: Ukraine is a puppet...  0.296296\n",
      "41   CC: Criticism of climate policies: Climate pol...  0.296296\n",
      "77   URW: Discrediting Ukraine: Discrediting Ukrain...  0.320000\n",
      "74   URW: Blaming the war on others rather than the...  0.326923\n",
      "88   URW: Discrediting the West, Diplomacy: The Wes...  0.347826\n",
      "110  URW: Russia is the Victim: Russia actions in U...  0.352941\n",
      "3                    CC: Criticism of climate movement  0.363636\n",
      "79                    URW: Discrediting Ukraine: Other  0.372093\n",
      "109                   URW: Russia is the Victim: Other  0.375000\n",
      "12   URW: Blaming the war on others rather than the...  0.376238\n",
      "4                    CC: Criticism of climate policies  0.380952\n",
      "25                 CC: Amplifying Climate Fears: Other  0.386364\n",
      "45   CC: Criticism of institutions and authorities:...  0.415094\n",
      "86        URW: Discrediting the West, Diplomacy: Other  0.415584\n",
      "20                           URW: Russia is the Victim  0.423077\n",
      "72   URW: Amplifying war-related fears: There is a ...  0.428571\n",
      "19                               URW: Praise of Russia  0.446429\n",
      "44   CC: Criticism of institutions and authorities:...  0.448276\n",
      "11                   URW: Amplifying war-related fears  0.482270\n",
      "22   CC: Amplifying Climate Fears: Amplifying exist...  0.500000\n",
      "13                           URW: Discrediting Ukraine  0.560345\n",
      "14               URW: Discrediting the West, Diplomacy  0.565445\n",
      "61   CC: Hidden plots by secret schemes of powerful...  0.588235\n",
      "5        CC: Criticism of institutions and authorities  0.608696\n",
      "0                         CC: Amplifying Climate Fears  0.691729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.utils.metrics import get_per_class_f1_scores\n",
    "\n",
    "# --- Step 5: Get Per-Class F1 Scores with Optimal Thresholds ---\n",
    "print(\"\\n--- Calculating Per-Class F1 Scores with Best Thresholds ---\")\n",
    "\n",
    "# We need to identify which columns in our label tensors correspond to narratives vs. sub-narratives\n",
    "narrative_indices = [i for i, label in id_to_label.items() if label.count(':') == 1]\n",
    "subnarrative_indices = [i for i, label in id_to_label.items() if label.count(':') == 2]\n",
    "\n",
    "# Use the dedicated function to get the F1 scores per class\n",
    "per_class_f1_df = get_per_class_f1_scores(\n",
    "    true_labels=val_true_labels,\n",
    "    pred_logits=val_logits,\n",
    "    id_to_label_map=id_to_label,\n",
    "    narrative_indices=narrative_indices,\n",
    "    subnarrative_indices=subnarrative_indices,\n",
    "    narrative_threshold=NARRATIVE_THRESHOLD, # Using the constant from the top of the notebook\n",
    "    subnarrative_threshold=SUBNARRATIVE_THRESHOLD # Using the constant from the top of the notebook\n",
    ")\n",
    "\n",
    "print(\"\\nPer-Class F1 Scores (sorted by F1 score):\")\n",
    "# Display the full dataframe to see all classes\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(per_class_f1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45c4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Least Performing Narratives (Bottom 30%) ---\n",
      "                                              label  f1_score\n",
      "1                  CC: Climate change is beneficial       0.0\n",
      "2          CC: Controversy about green technologies       0.0\n",
      "6                    CC: Downplaying climate change       0.0\n",
      "7   CC: Green policies are geopolitical instruments       0.0\n",
      "15                      URW: Distrust towards Media       0.0\n",
      "9      CC: Questioning the measurements and science       0.0\n",
      "\n",
      "--- Least Performing Subnarratives (Bottom 30%) ---\n",
      "                                                label  f1_score\n",
      "30  CC: Controversy about green technologies: Nucl...       0.0\n",
      "24  CC: Amplifying Climate Fears: Earth will be un...       0.0\n",
      "26  CC: Amplifying Climate Fears: Whatever we do i...       0.0\n",
      "27  CC: Climate change is beneficial: CO2 is benef...       0.0\n",
      "28            CC: Climate change is beneficial: Other       0.0\n",
      "31    CC: Controversy about green technologies: Other       0.0\n",
      "29  CC: Climate change is beneficial: Temperature ...       0.0\n",
      "50  CC: Downplaying climate change: Human activiti...       0.0\n",
      "51  CC: Downplaying climate change: Humans and nat...       0.0\n",
      "52  CC: Downplaying climate change: Ice is not mel...       0.0\n",
      "53              CC: Downplaying climate change: Other       0.0\n",
      "54  CC: Downplaying climate change: Sea levels are...       0.0\n",
      "47  CC: Criticism of institutions and authorities:...       0.0\n",
      "40  CC: Criticism of climate policies: Climate pol...       0.0\n",
      "43  CC: Criticism of institutions and authorities:...       0.0\n",
      "46  CC: Criticism of institutions and authorities:...       0.0\n",
      "37  CC: Criticism of climate movement: Climate mov...       0.0\n",
      "35  CC: Criticism of climate movement: Ad hominem ...       0.0\n",
      "34  CC: Controversy about green technologies: Rene...       0.0\n",
      "33  CC: Controversy about green technologies: Rene...       0.0\n",
      "32  CC: Controversy about green technologies: Rene...       0.0\n",
      "56  CC: Downplaying climate change: Weather sugges...       0.0\n",
      "57  CC: Green policies are geopolitical instrument...       0.0\n",
      "58  CC: Green policies are geopolitical instrument...       0.0\n",
      "59  CC: Green policies are geopolitical instrument...       0.0\n",
      "63  CC: Questioning the measurements and science: ...       0.0\n",
      "62  CC: Hidden plots by secret schemes of powerful...       0.0\n",
      "55  CC: Downplaying climate change: Temperature in...       0.0\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Identify Least Performing Narratives and Subnarratives (Bottom 30%) ---\n",
    "\n",
    "# Separate narratives and subnarratives by label format\n",
    "narratives_df = per_class_f1_df[per_class_f1_df['label'].apply(lambda x: x.count(':') == 1)]\n",
    "subnarratives_df = per_class_f1_df[per_class_f1_df['label'].apply(lambda x: x.count(':') == 2)]\n",
    "\n",
    "# Calculate bottom 30% count for each\n",
    "narr_bottom_n = max(1, int(len(narratives_df) * 0.3))\n",
    "subnarr_bottom_n = max(1, int(len(subnarratives_df) * 0.3))\n",
    "\n",
    "least_perf_narratives = narratives_df.nsmallest(narr_bottom_n, 'f1_score')\n",
    "least_perf_subnarratives = subnarratives_df.nsmallest(subnarr_bottom_n, 'f1_score')\n",
    "\n",
    "print(\"\\n--- Least Performing Narratives (Bottom 30%) ---\")\n",
    "print(least_perf_narratives[['label', 'f1_score']])\n",
    "\n",
    "print(\"\\n--- Least Performing Subnarratives (Bottom 30%) ---\")\n",
    "print(least_perf_subnarratives[['label', 'f1_score']])\n",
    "\n",
    "# Save as CSV for easy inspection and re-use\n",
    "least_perf_narratives.to_csv('least_perf_narratives.csv', index=False)\n",
    "least_perf_subnarratives.to_csv('least_perf_subnarratives.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a4324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
