{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44df6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "# Set the current working directory to the project root\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad8a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "narratives",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "subnarratives",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "narrative_ids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "subnarrative_ids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "num_narratives",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_subnarratives",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count_bin",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "labels",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b5e1706e-3006-4be7-935e-ef41b447edc9",
       "rows": [
        [
         "0",
         "BG_670.txt",
         "Опитът на колективния Запад да „обезкърви Русия“ с ръцете на властите в Киев „се провали с гръм и трясък“ и скоро от Украйна ...\n\nОпитът на колективния Запад да „обезкърви Русия“ с ръцете на властите в Киев „се провали с гръм и трясък“ и скоро от Украйна няма да остане почти нищо, ако не започне процесът на разрешаване на този въоръжен конфликт. Тази гледна точка изрази пред ТАСС бившият началник на кабинета на държавния секретар на САЩ Колин Пауъл, пенсионирания полковник от армията на САЩ Лорънс Уилкерсън.\n\"Подкрепата на САЩ, НАТО и други западни съюзници за войната в Украйна срещу Русия е безумна. Това води до смъртта на украински войници в името на загубена кауза, ако не вземете предвид печеленето на пари от американски и европейски военни изпълнители, както и бруталния опит да се обезкърви Русия чрез трети страни“, каза Уилкерсън.\n\"Усилията за постигане на тази последна цел, при цялата ѝ подлост, се провалиха с гръм и трясък\", заяви видният американски военен анализатор. - В действителност Русия очевидно побеждава\". Ако скоро не бъде обявено прекратяване на огъня и не бъде свикана истинска мирна конференция, тогава от Украйна практически нищо няма да остане“, убеден е Уилкерсън. Той спомена \"истинска мирна конференция\" в противовес на срещата в Бюргенсток (Швейцария), която беше свикана на 15-16 юни по инициатива на Запада и на която Русия не беше поканена. Дори много западни политически анализатори заявиха след срещата, че тя е претърпяла фиаско. Нито една страна от БРИКС не подкрепи заключителния документ от срещата.",
         "['URW: Blaming the war on others rather than the invader'\n 'URW: Discrediting the West, Diplomacy'\n 'URW: Discrediting the West, Diplomacy'\n 'URW: Amplifying war-related fears']",
         "['URW: Blaming the war on others rather than the invader: The West are the aggressors'\n 'URW: Discrediting the West, Diplomacy: Other'\n 'URW: Discrediting the West, Diplomacy: The West does not care about Ukraine, only about its interests'\n 'URW: Amplifying war-related fears: Other']",
         "BG",
         "[11, 12, 14]",
         "[88, 70, 74, 86]",
         "4",
         "4",
         "248",
         "101-250",
         "[0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0]"
        ],
        [
         "1",
         "A7_URW_BG_4793.txt",
         "Цончо Ганев, “Възраждане”: Обещали сме на Украйна боеприпаси, ракети, както и над 40 танка. Затова ли Радев отказа за срещата на НАТО\n\n“Възраждане” иска да информация каква е позицията на България за Срещата на върха на НАТО\nСпоред документи на украинската държава, България ще им подари над 40 танка, ракети и много военна техника\n„НАТО е всичко друго, но не и отбранителен съюз. Ние винаги сме били на позиция, че държавата ни няма място в какъвто и да е военен блок, винаги сме смятали, че България не трябва да е част от НАТО, но за да сме максимално демократични, нашата позиция е, че българският народ трябва да се произнесе и трябва да има референдум дали да сме член на НАТО или не.“, каза от трибуната на Народното събрание заместник-председателят на „Възраждане“ Цончо Ганев в декларация прочетена от парламентарната група.\nСпоред него, Съединените американски щати може и да провеждат мироопазващи военни операции, например в Сирия, Ирак, Афганистан и в ред други държави, но по съвсем консервативни данни през последните 70 години жертвите в техни мироопазващи военни операции са повече от 40 милиона души.\n„Ако вземем за пример специалната военна операция, ще видим, че от една страна е Русия, от друга - Украйна, която разчита на издръжката и подкрепата на НАТО, от което България също е част. За да е пълна подигравката, още когато започна тази специална военна операция, тогавашното правителство на Кирил Петков, Атанасов, Христо Иванов. Слави Трифонов и Корнелия Нинова, започна да продава оръжия през посредници до украинската граница. Стигнахме дотам, че следващите наши правителства вече подаряваха оръжие, включително и служебните правителства на Радев, които опразниха част от складовете ни с военна техника.“, коментира още Ганев.\nСпоред официална информация, която излиза, е видно, че към днешна дата този военен конфликт върви към развръзка и това вече не се крие дори от държавите членки на НАТО, а украинската държава губи все повече територии.\n„След вчерашните изявления на Зеленски става ясно, че войната трябва да се прекрати и да се направи това, което искат руските интереси в целия този многопластов проблем. Притеснителното е, че България е част от него. Повече от 4 години във Варна има команден център на НАТО и България вече е изправена пред угрозата да бъде атакувана, ако конфликтът се разрасне.“, допълни Ганев.\nТой припомни, че след няколко дни предстои Среща на върха на НАТО в САЩ, на която Президентът няма да присъства.\n„Видяхме официални документи на украинската държава, в които пише, че нашата страна е поела отговорност за изпращането и подаряването на военна техника, на снаряжение, на боеприпаси, на ракетите ни, както и над 40 танка. Каква е опасността пред държавата ни, че чак Президентът не иска да отиде на Срещата на върха? Това е нещото, на което трябва да отговори евроатлантическото правителство, защото касае нашата национална сигурност и ако пари се печелят, бюджет и приходи се изравняват и се възстановяват, от войната няма връщане назад. Защото цар Борис Трети е казал „по-добре да ядем черен хляб, отколкото майките и жените ни да носят черни забрадки.“, каза в заключение Цончо Ганев.",
         "['URW: Discrediting Ukraine']",
         "['URW: Discrediting Ukraine: Situation in Ukraine is hopeless']",
         "BG",
         "[13]",
         "[81]",
         "1",
         "1",
         "503",
         "501-1000",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0]"
        ],
        [
         "2",
         "BG_3245.txt",
         "Подкрепата за Киев от страна на Запада вече не изглежда непоклатима\n\nВ деня на 80-ата годишнина от десанта на съюзниците в Нормандия конфликтът в Украйна продължава на фона на нестабилността на Западния фронт.\nНа тържествените мероприятия лидерите на западните страни ще демонстрират единен фронт: ще положат венци пред гробовете на загиналите и ще обещаят непоколебима подкрепа на Киев. Но настроенията на бойните полета в Украйна и мащабните промени в глобалната политика говорят друго.\nПодкрепата на Запада, който до тази година осигуряваше доставките на оръжие за Киев, вече не изглежда непоклатима.\nОбещанията за подкрепа и солидарност с Украйна може да се окажат празни, тъй като светът се подготвя за потенциални сеизмични промени. Европейците се опасяват, че ако тази есен Байдън загуби от Тръмп в борбата за Белия дом, Украйна може да загуби най-важния си съюзник.\nИ дори ако Джо Байдън бъде преизбран, не всички членове на неговата администрация ще искат да обединят сили с Украйна и да оглавят победоносно контранастъпление срещу Русия, заяви френският политолог Никола Тензер.\nМеждувременно в цяла Европа традиционните партии се опасяват, че крайната десница може да спечели голяма победа на започващите избори за Европейски парламент Тази седмица.",
         "['URW: Discrediting the West, Diplomacy' 'URW: Discrediting Ukraine'\n 'URW: Discrediting the West, Diplomacy']",
         "['URW: Discrediting the West, Diplomacy: The West is weak'\n 'URW: Discrediting Ukraine: Situation in Ukraine is hopeless'\n 'URW: Discrediting the West, Diplomacy: The EU is divided']",
         "BG",
         "[13, 14]",
         "[81, 90, 87]",
         "3",
         "3",
         "190",
         "101-250",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0]"
        ],
        [
         "3",
         "A9_BG_5190.txt",
         "Дмитрий Медведев: НПО-та, спонсорирани от Сорос, са съучастници на терористите в Киев\n\nЗаместник-председателят на руския Съвет за сигурност Дмитрий Медведев заяви, че Международната федерация за правата на човека (FIDH), финансирана от фондация \"Отворено общество\" (призната за нежелана в Русия) на милиардера Джордж Сорос, която се обърна към Международния наказателен съд с искане за издаване на заповед за арест, е \"съучастник на терористите в Киев\", предават РИА Новости и \"Фокус\".\nМеждународната федерация за правата на човека на Сорос (FIDH) и външните министерства на редица западни държави отправят искане до прокуратурата на Международния наказателен съд за издаване на заповеди за \"арест\" на заместник-председателя на руския Съвет за сигурност и бивш президент и премиер на РФ Дмитрий Медведев, заместник-началника на администрацията на руския президент Алексей Громов и редица руски журналисти.\n\"Колко е приятно да получим признание за ефективността на съвместните ни усилия срещу неонацисткия режим в Киев! То дойде от гадни организации като неправителствените организации, собственост на отвратителния стар герой Сорос, който отиде в Международния наказателен съд заради нашата скромна работа. Такива НПО-та и техните господари са съучастници на терористите, които само вчера убиха повече от 20 наши цивилни граждани\", написа Медведев в социалната мрежа X.\nМедведев отбелязва, че това го е мотивирало да продължи работата си срещу \"подлата нацистка клика\".\nПо-рано директорът по правните въпроси на проекта Docket на фондация \"Клуни\" Анна Нейстат заяви, че организацията се стреми в Европа да бъдат издадени заповеди за арест на руски журналисти. Съоснователи на фондация \"Клуни\" са актьорът Джордж Клуни и съпругата му Амал.\nКакто самият Джордж Клуни обясни по-късно, фондацията \"се е изразила погрешно\" и организацията, която има \"дълга история на защита на журналисти, никога няма да ги преследва\".",
         "['URW: Discrediting the West, Diplomacy' 'URW: Discrediting Ukraine']",
         "['URW: Discrediting the West, Diplomacy: Other'\n 'URW: Discrediting Ukraine: Ukraine is associated with nazism']",
         "BG",
         "[13, 14]",
         "[84, 86]",
         "2",
         "2",
         "275",
         "251-500",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0]"
        ],
        [
         "4",
         "A9_BG_3379.txt",
         "Британски дипломат обвини Запада за украинския конфликт — Responsible Statecraft\n\nБритански дипломат обвини Запада за украинския конфликт — Responsible Statecraft\nВ условията на трескаво лобиране от страна на Запада за изостряне на конфликта, много липсват гласовете на разума и на несъгласните с опосредстваната война на НАТО с Русия в Украйна, пише Responsible Statecraft. Но ги има. Сред тях е бившият икономически съветник на британското посолство в Москва Иън Прауд.\nВ книгата си \"Неудачникът в Москва: Как се провали британската дипломация в Русия?\" Прауд разказва, че след началото на украинската криза през 2014 г.за Лондон стана самоцел да накаже Русия с помощта на санкции и изолация. Прауд предупреждавал, че санкциите само ще вдъхновят Русия да се стреми към самодостатъчност. Обаче не го послушаха.\nТой беше особено впечатлен от това как Москва се справи с нестабилността, причинена от комбинация от западни санкции и намаляване на цените на енергията. А към момента на началото на СВО Русия вече можеше да сдържа опитите на западните страни да дестабилизират рублата и да сринат руската икономика.\nПрауд каза, че Лондон е допринесъл за провала на Минските споразумения, когато е убедил Европейския съвет да се съгласи, че санкциите срещу Русия няма да бъдат отменени до пълното изпълнение на споразуменията. Това даде на Киев допълнителен стимул да саботира тяхното спазване. Но Москва, за разлика от Киев, беше наистина заинтересована от изпълнението на споразуменията. Освен това Русия беше единствената страна по тези споразумения, която действаше добросъвестно.",
         "['URW: Discrediting the West, Diplomacy' 'URW: Praise of Russia']",
         "['URW: Discrediting the West, Diplomacy: Other'\n 'URW: Praise of Russia: Other']",
         "BG",
         "[19, 14]",
         "[86, 103]",
         "2",
         "2",
         "237",
         "101-250",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 0 0 0 0]"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>language</th>\n",
       "      <th>narrative_ids</th>\n",
       "      <th>subnarrative_ids</th>\n",
       "      <th>num_narratives</th>\n",
       "      <th>num_subnarratives</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_bin</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>BG</td>\n",
       "      <td>[11, 12, 14]</td>\n",
       "      <td>[88, 70, 74, 86]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "      <td>101-250</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A7_URW_BG_4793.txt</td>\n",
       "      <td>Цончо Ганев, “Възраждане”: Обещали сме на Укра...</td>\n",
       "      <td>[URW: Discrediting Ukraine]</td>\n",
       "      <td>[URW: Discrediting Ukraine: Situation in Ukrai...</td>\n",
       "      <td>BG</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>503</td>\n",
       "      <td>501-1000</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG_3245.txt</td>\n",
       "      <td>Подкрепата за Киев от страна на Запада вече не...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy: The We...</td>\n",
       "      <td>BG</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>[81, 90, 87]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>101-250</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A9_BG_5190.txt</td>\n",
       "      <td>Дмитрий Медведев: НПО-та, спонсорирани от Соро...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy: Other,...</td>\n",
       "      <td>BG</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>[84, 86]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>251-500</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A9_BG_3379.txt</td>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: P...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy: Other,...</td>\n",
       "      <td>BG</td>\n",
       "      <td>[19, 14]</td>\n",
       "      <td>[86, 103]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>101-250</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0          BG_670.txt  Опитът на колективния Запад да „обезкърви Руси...   \n",
       "1  A7_URW_BG_4793.txt  Цончо Ганев, “Възраждане”: Обещали сме на Укра...   \n",
       "2         BG_3245.txt  Подкрепата за Киев от страна на Запада вече не...   \n",
       "3      A9_BG_5190.txt  Дмитрий Медведев: НПО-та, спонсорирани от Соро...   \n",
       "4      A9_BG_3379.txt  Британски дипломат обвини Запада за украинския...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0  [URW: Blaming the war on others rather than th...   \n",
       "1                        [URW: Discrediting Ukraine]   \n",
       "2  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "3  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "4  [URW: Discrediting the West, Diplomacy, URW: P...   \n",
       "\n",
       "                                       subnarratives language narrative_ids  \\\n",
       "0  [URW: Blaming the war on others rather than th...       BG  [11, 12, 14]   \n",
       "1  [URW: Discrediting Ukraine: Situation in Ukrai...       BG          [13]   \n",
       "2  [URW: Discrediting the West, Diplomacy: The We...       BG      [13, 14]   \n",
       "3  [URW: Discrediting the West, Diplomacy: Other,...       BG      [13, 14]   \n",
       "4  [URW: Discrediting the West, Diplomacy: Other,...       BG      [19, 14]   \n",
       "\n",
       "   subnarrative_ids  num_narratives  num_subnarratives  word_count  \\\n",
       "0  [88, 70, 74, 86]               4                  4         248   \n",
       "1              [81]               1                  1         503   \n",
       "2      [81, 90, 87]               3                  3         190   \n",
       "3          [84, 86]               2                  2         275   \n",
       "4         [86, 103]               2                  2         237   \n",
       "\n",
       "  word_count_bin                                             labels  \n",
       "0        101-250  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, ...  \n",
       "1       501-1000  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "2        101-250  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "3        251-500  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "4        101-250  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_management.loaders import load_labeled_df\n",
    "\n",
    "df = load_labeled_df('phase0_baseline_labeled.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943059d",
   "metadata": {},
   "source": [
    "# Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51aafd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1699, 12)\n",
      "Train set shape: (992, 12)\n",
      "Validation set shape: (337, 12)\n",
      "Test set shape: (370, 12)\n",
      "\n",
      "Example of train_df head:\n",
      "                    id                                               text  \\\n",
      "1   A7_URW_BG_4793.txt  Цончо Ганев, “Възраждане”: Обещали сме на Укра...   \n",
      "5   A7_URW_BG_3566.txt  Ответните мерки ще бъдат крайно болезнени за Е...   \n",
      "6           BG_855.txt  Русия забрани разпространението на десетки мед...   \n",
      "7           BG_751.txt  US военен: Путин ни изигра така, както Рейгън ...   \n",
      "13          BG_573.txt  На 19 и 21 юни киевският режим извърши поредни...   \n",
      "\n",
      "                                           narratives  \\\n",
      "1                         [URW: Discrediting Ukraine]   \n",
      "5   [URW: Discrediting Ukraine, URW: Negative Cons...   \n",
      "6   [URW: Distrust towards Media, URW: Distrust to...   \n",
      "7   [URW: Praise of Russia, URW: Discrediting Ukra...   \n",
      "13  [URW: Blaming the war on others rather than th...   \n",
      "\n",
      "                                        subnarratives language narrative_ids  \\\n",
      "1   [URW: Discrediting Ukraine: Situation in Ukrai...       BG          [13]   \n",
      "5   [URW: Discrediting Ukraine: Ukraine is a puppe...       BG  [17, 13, 14]   \n",
      "6   [URW: Distrust towards Media: Other, URW: Dist...       BG      [20, 15]   \n",
      "7   [URW: Praise of Russia: Praise of Russian Pres...       BG  [19, 12, 13]   \n",
      "13  [URW: Blaming the war on others rather than th...       BG      [12, 13]   \n",
      "\n",
      "    subnarrative_ids  num_narratives  num_subnarratives  word_count  \\\n",
      "1               [81]               1                  1         503   \n",
      "5   [88, 97, 83, 86]               4                  4         498   \n",
      "6      [92, 109, 94]               3                  3         339   \n",
      "7      [104, 74, 83]               3                  3         493   \n",
      "13          [75, 76]               2                  2         330   \n",
      "\n",
      "   word_count_bin                                             labels  \n",
      "1        501-1000  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
      "5         251-500  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
      "6         251-500  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "7         251-500  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
      "13        251-500  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df.index.to_numpy().reshape(-1, 1)\n",
    "y = np.array(df['labels'].tolist())\n",
    "\n",
    "train_val_indices, y_train_val, test_indices, y_test = iterative_train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "train_indices, y_train, val_indices, y_val = iterative_train_test_split(train_val_indices, y_train_val, test_size = 0.25)\n",
    "\n",
    "train_df = df.loc[train_indices.flatten()]\n",
    "val_df = df.loc[val_indices.flatten()]\n",
    "test_df = df.loc[test_indices.flatten()]\n",
    "\n",
    "\n",
    "# 5. Verify the results\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\nExample of train_df head:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4129a73a",
   "metadata": {},
   "source": [
    "# Tokenizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2416b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total labels: 117\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "num_total_labels = df['labels'].iloc[0].shape[0]\n",
    "print(f\"Number of total labels: {num_total_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a9b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_management.label_parser import get_label_mappings\n",
    "\n",
    "label_to_id, id_to_label, narrative_to_subnarrative_ids = get_label_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b9cc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels = num_total_labels,\n",
    "    problem_type = 'multi_label_classification',\n",
    "    id2label = id_to_label,\n",
    "    label2id = label_to_id \n",
    ")\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5827788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PyTorch datasets...\n"
     ]
    }
   ],
   "source": [
    "from src.data_management.datasets import NarrativeClassificationDataset\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "print(\"Creating PyTorch datasets...\")\n",
    "train_dataset = NarrativeClassificationDataset(\n",
    "    train_df,\n",
    "    tokenizer,\n",
    "    max_length = MAX_LENGTH,\n",
    ")\n",
    "\n",
    "test_dataset = NarrativeClassificationDataset(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    max_length = MAX_LENGTH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f107c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataLoaders...\n",
      "DataLoaders created successfully.\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 117])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "print(\"Creating DataLoaders...\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "print(\"DataLoaders created successfully.\")\n",
    "for batch in train_dataloader:\n",
    "    print(batch['input_ids'].shape) # Should be [BATCH_SIZE, MAX_TOKEN_LEN]\n",
    "    print(batch['labels'].shape)    # Should be [BATCH_SIZE, num_total_labels]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f703f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=117, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move your model to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be98987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer created successfully.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "print(\"Optimizer created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71579c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler created successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "EPOCH = 3\n",
    "num_training_steps = len(train_dataloader) * EPOCH\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps\n",
    ")\n",
    "\n",
    "print(\"Scheduler created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b2eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "MODEL_OUTPUT_PATH = 'models/phase0_baseline_model.pt'\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "    \n",
    "def compute_f1_metrics(preds, labels, threshold=0.5):\n",
    "    # preds are the raw logits, labels are the multi-hot encoded true values\n",
    "    sigmoid_preds = 1 / (1 + np.exp(-preds)) # Apply sigmoid to convert logits to probabilities\n",
    "    binary_preds = (sigmoid_preds > threshold).astype(int) # Apply threshold to get binary predictions\n",
    "    \n",
    "    f1_micro = f1_score(y_true=labels, y_pred=binary_preds, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(y_true=labels, y_pred=binary_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    roc_auc_micro = roc_auc_score(y_true=labels, y_score=sigmoid_preds, average='micro')\n",
    "    roc_auc_macro = roc_auc_score(y_true=labels, y_score=sigmoid_preds, average='macro')\n",
    "\n",
    "    return {\"f1_micro\": f1_micro, \"f1_macro\": f1_macro, \"roc_auc_micro\": roc_auc_micro, \"roc_auc_macro\": roc_auc_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "233940b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [04:08<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.1304\n",
      "Running evaluation on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [00:58<00:00,  2.45s/it]\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Preds Stats: Min=0.0120, Max=0.2251, Mean=0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [04:10<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.1287\n",
      "Running evaluation on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [00:58<00:00,  2.45s/it]\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Preds Stats: Min=0.0105, Max=0.2261, Mean=0.0392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [04:11<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.1282\n",
      "Running evaluation on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [00:59<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Preds Stats: Min=0.0100, Max=0.2232, Mean=0.0386\n",
      "\n",
      "--- Training Complete ---\n",
      "Best F1 Micro score achieved: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/twoface/Documents/Passau/masterarbeit/hybrid-text-classification/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Starting the training process...\")\n",
    "best_f1_score = 0.0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # --- Evaluation Phase ---\n",
    "    print(\"Running evaluation on the test set...\")\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    \n",
    "    all_preds_logits = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            # Move batch data to the device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass to get logits\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Move logits and labels to CPU and convert to numpy arrays to accumulate them\n",
    "            all_preds_logits.append(logits.cpu().numpy())\n",
    "            all_true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Concatenate all logits and labels\n",
    "    all_preds_logits = np.concatenate(all_preds_logits, axis=0)\n",
    "    all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "    sigmoid_preds = 1 / (1 + np.exp(-all_preds_logits))\n",
    "    print(f\"Sigmoid Preds Stats: Min={np.min(sigmoid_preds):.4f}, Max={np.max(sigmoid_preds):.4f}, Mean={np.mean(sigmoid_preds):.4f}\")\n",
    "    # Compute F1 metrics\n",
    "    eval_metrics = compute_f1_metrics(all_preds_logits, all_true_labels)\n",
    "    current_f1 = eval_metrics['f1_micro']\n",
    "    if current_f1 > best_f1_score:\n",
    "        best_f1_score = current_f1\n",
    "        print(f\"New best F1 score ({best_f1_score:.4f})! Saving model to {MODEL_OUTPUT_PATH}\")\n",
    "        torch.save(model.state_dict(), MODEL_OUTPUT_PATH)\n",
    "        \n",
    "print(\"\\n--- Training Complete ---\")\n",
    "print(f\"Best F1 Micro score achieved: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8b9c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "f1_macro = eval_metrics['f1_macro']\n",
    "print(f\"F1 Macro score: {f1_macro:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
